{'env_id': 'deep-sea-treasure-v0', 'learning_rate': 0.0003, 'initial_epsilon': 0.01, 'epsilon_decay_steps:': None, 'batch_size': 128, 'per': True, 'gpi_pd': False, 'alpha_per': 0.6, 'min_priority': 0.01, 'tau': 1.0, 'num_nets': 2, 'clip_grand_norm': None, 'target_net_update_freq': 1000, 'gamma': 0.99, 'net_arch': [256, 256, 256, 256], 'dynamics_model_arch': [256, 256, 256], 'gradient_updates': 20, 'buffer_size': 1000000, 'learning_starts': 100, 'dyna': False, 'dynamics_rollout_len': 1, 'dynamics_uncertainty_threshold': 1.5, 'dynamics_rollout_starts': 5000, 'dynamics_rollout_freq': 250, 'dynamics_rollout_batch_size': 25000, 'dynamics_buffer_size': 100000, 'dynamics_normalize_inputs': False, 'dynamics_ensemble_size': 5, 'dynamics_num_elites': 2, 'real_ratio': 0.5, 'drop_rate': 0.01, 'layer_norm': True, 'seed': 42}
Training starts... Let's roll!
gpi_pd:False
from 10 demos, find 11 corner weights
w:[0. 1.]
w:[0.212 0.788]
w:[0.391 0.609]
w:[0.47 0.53]
w:[0.511 0.489]
w:[0.541 0.459]
w:[0.589 0.411]
w:[0.666 0.334]
w:[0.672 0.328]
w:[0.704 0.296]
w:[1. 0.]
rews_demo_dict:{(0.6860699653625488, -2.970099985599518): [2, 2, 1], (7.876887321472168, -4.9009950160980225): [2, 2, 3, 1, 1], (10.827021598815918, -6.793465197086334): [2, 2, 3, 3, 1, 1, 1], (12.918425559997559, -8.648275256156921): [2, 2, 3, 3, 3, 1, 1, 1, 1], (13.794110298156738, -9.561792492866516): [2, 2, 3, 3, 3, 3, 1, 1, 1, 1], (14.560551643371582, -10.4661745429039): [2, 2, 3, 3, 3, 3, 3, 1, 1, 1, 1], (17.02741813659668, -13.99416446685791): [2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1], (17.459184646606445, -14.85422283411026): [2, 2, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1], (18.69310760498047, -17.383137583732605): [2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1], (19.3843936920166, -19.027213096618652): [2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
W_corner: [array([1., 0.]), array([0.39080246, 0.60919754]), array([0.51056338, 0.48943662]), array([0.58851004, 0.41148996]), array([0.70399075, 0.29600925]), array([0.6720793, 0.3279207]), array([0.66573773, 0.33426227]), array([0.54126519, 0.45873481]), array([0.47002179, 0.52997821]), array([0.21168203, 0.78831797]), array([0., 1.])] W_corner size: 11
CCS: [array([ 0.68606997, -2.97009999]), array([ 7.87688732, -4.90099502]), array([10.8270216, -6.7934652]), array([12.91842556, -8.64827526]), array([13.7941103 , -9.56179249]), array([ 14.56055164, -10.46617454]), array([ 17.02741814, -13.99416447]), array([ 17.45918465, -14.85422283]), array([ 18.6931076 , -17.38313758]), array([ 19.38439369, -19.0272131 ])] CCS size: 10
Next weight: [1. 0.]
Next weight vector: [1. 0.]
change_w_every_episode:True
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 100, Time: 0.15521599352359772
Total Reward: [   0. -100.], Discounted: [  0.       -62.762794]
Scalarized Reward: 0.0, Discounted: 0.0
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.20009200274944305
Total Reward: [14. -9.], Discounted: [12.789242 -8.561792]
Scalarized Reward: 2.742957746478875, Discounted: 2.339263801843349
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2681120038032532
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.05744199827313423
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2633019983768463
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.20534099638462067
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
Episode infos:
Steps: 10, Time: 0.1285170018672943
Total Reward: [ 15.1 -10. ], Discounted: [13.65617  -9.466174]
Scalarized Reward: 3.585756385780832, Discounted: 3.0491457193228255
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
Episode infos:
Steps: 10, Time: 0.13454799354076385
Total Reward: [ 15.1 -10. ], Discounted: [13.65617  -9.466174]
Scalarized Reward: 3.585756385780832, Discounted: 3.0491457193228255
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
Episode infos:
Steps: 3, Time: 0.03130299970507622
Total Reward: [ 0.7 -3. ], Discounted: [ 0.6792093 -2.940399 ]
Scalarized Reward: -3.000000000000068, Discounted: -2.9403989315033625
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
Episode infos:
Steps: 7, Time: 0.08824899792671204
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 1.6954031726724552, Discounted: 1.4736623308250394
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
Episode infos:
Steps: 7, Time: 0.08698300272226334
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 1.6954031726724552, Discounted: 1.4736623308250394
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.25614500045776367
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.25330400466918945
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.27859100699424744
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.27973899245262146
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.25488999485969543
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
Episode infos:
Steps: 10, Time: 0.12820400297641754
Total Reward: [ 15.1 -10. ], Discounted: [13.65617  -9.466174]
Scalarized Reward: 3.585756385780832, Discounted: 3.0491457193228255
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.057312000542879105
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
Episode infos:
Steps: 3, Time: 0.029715999960899353
Total Reward: [ 0.7 -3. ], Discounted: [ 0.6792093 -2.940399 ]
Scalarized Reward: -3.000000000000068, Discounted: -2.9403989315033625
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.25309398770332336
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.25393301248550415
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.11367800086736679
Total Reward: [14. -9.], Discounted: [12.789242 -8.561792]
Scalarized Reward: 2.742957746478875, Discounted: 2.339263801843349
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.2505069971084595
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.252903014421463
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.1983029991388321
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.056839000433683395
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.05716700106859207
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.2793959975242615
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.19784900546073914
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
Episode infos:
Steps: 10, Time: 0.12595400214195251
Total Reward: [ 15.1 -10. ], Discounted: [13.65617  -9.466174]
Scalarized Reward: 3.585756385780832, Discounted: 3.0491457193228255
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.0861629992723465
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 0.22984553752115744, Discounted: 0.09173792789933977
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.19805499911308289
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.19888700544834137
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.19631199538707733
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.19747500121593475
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.11282700300216675
Total Reward: [14. -9.], Discounted: [12.789242 -8.561792]
Scalarized Reward: 2.742957746478875, Discounted: 2.339263801843349
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
Episode infos:
Steps: 7, Time: 0.0859069973230362
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 1.6954031726724552, Discounted: 1.4736623308250394
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
Episode infos:
Steps: 10, Time: 0.12675899267196655
Total Reward: [ 15.1 -10. ], Discounted: [13.65617  -9.466174]
Scalarized Reward: 3.585756385780832, Discounted: 3.0491457193228255
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.29215601086616516
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.11484099924564362
Total Reward: [14. -9.], Discounted: [12.789242 -8.561792]
Scalarized Reward: 2.742957746478875, Discounted: 2.339263801843349
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2632260024547577
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.26321399211883545
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
Episode infos:
Steps: 3, Time: 0.03180700168013573
Total Reward: [ 0.7 -3. ], Discounted: [ 0.6792093 -2.940399 ]
Scalarized Reward: -3.000000000000068, Discounted: -2.9403989315033625
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
Episode infos:
Steps: 3, Time: 0.031429000198841095
Total Reward: [ 0.7 -3. ], Discounted: [ 0.6792093 -2.940399 ]
Scalarized Reward: -3.000000000000068, Discounted: -2.9403989315033625
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.2922210097312927
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
Episode infos:
Steps: 10, Time: 0.13527299463748932
Total Reward: [ 15.1 -10. ], Discounted: [13.65617  -9.466174]
Scalarized Reward: 3.585756385780832, Discounted: 3.0491457193228255
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
Episode infos:
Steps: 7, Time: 0.08515200018882751
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 1.6954031726724552, Discounted: 1.4736623308250394
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.19720099866390228
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.2802160084247589
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.19639599323272705
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.253726989030838
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.2527349889278412
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.25534799695014954
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.19845600426197052
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.11276199668645859
Total Reward: [14. -9.], Discounted: [12.789242 -8.561792]
Scalarized Reward: 2.742957746478875, Discounted: 2.339263801843349
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.19693000614643097
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2524529993534088
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.11384999752044678
Total Reward: [14. -9.], Discounted: [12.789242 -8.561792]
Scalarized Reward: 2.742957746478875, Discounted: 2.339263801843349
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.19691500067710876
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.19887900352478027
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.280707985162735
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.05827699974179268
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.25504299998283386
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2520979940891266
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.27829399704933167
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.0854720026254654
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 0.22984553752115744, Discounted: 0.09173792789933977
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.11267100274562836
Total Reward: [14. -9.], Discounted: [12.789242 -8.561792]
Scalarized Reward: 2.742957746478875, Discounted: 2.339263801843349
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.0846019983291626
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 0.22984553752115744, Discounted: 0.09173792789933977
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
roll back guide policy; from [2, 2, 3, 1, 1]
TO: [2, 2, 3, 1]
Episode infos:
Steps: 5, Time: 0.05729300156235695
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.19564099609851837
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
Episode infos:
Steps: 3, Time: 0.02928199991583824
Total Reward: [ 0.7 -3. ], Discounted: [ 0.6792093 -2.940399 ]
Scalarized Reward: -3.000000000000068, Discounted: -2.9403989315033625
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2531050145626068
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
Episode infos:
Steps: 10, Time: 0.12665200233459473
Total Reward: [ 15.1 -10. ], Discounted: [13.65617  -9.466174]
Scalarized Reward: 3.585756385780832, Discounted: 3.0491457193228255
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.05783500149846077
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
Episode infos:
Steps: 10, Time: 0.12691499292850494
Total Reward: [ 15.1 -10. ], Discounted: [13.65617  -9.466174]
Scalarized Reward: 3.585756385780832, Discounted: 3.0491457193228255
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.19811199605464935
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.19637300074100494
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.19654099643230438
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.25107601284980774
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
Episode infos:
Steps: 7, Time: 0.08460599929094315
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 1.6954031726724552, Discounted: 1.4736623308250394
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.25237300992012024
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.05740400031208992
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.19790300726890564
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.05693800002336502
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.25499001145362854
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.2014389932155609
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.2096399962902069
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.1982080042362213
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.05709100142121315
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.11410500109195709
Total Reward: [14. -9.], Discounted: [12.789242 -8.561792]
Scalarized Reward: 2.742957746478875, Discounted: 2.339263801843349
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
Episode infos:
Steps: 3, Time: 0.029549000784754753
Total Reward: [ 0.7 -3. ], Discounted: [ 0.6792093 -2.940399 ]
Scalarized Reward: -3.000000000000068, Discounted: -2.9403989315033625
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
Episode infos:
Steps: 7, Time: 0.08515200018882751
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 1.6954031726724552, Discounted: 1.4736623308250394
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.05765499919652939
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2546539902687073
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.20645900070667267
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
Episode infos:
Steps: 7, Time: 0.09174299985170364
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 1.6954031726724552, Discounted: 1.4736623308250394
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.2859799861907959
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.05790700018405914
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.08575399965047836
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 0.22984553752115744, Discounted: 0.09173792789933977
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.09363599866628647
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 0.22984553752115744, Discounted: 0.09173792789933977
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.08901199698448181
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 0.22984553752115744, Discounted: 0.09173792789933977
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2539829909801483
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.25111401081085205
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.28141799569129944
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
Episode infos:
Steps: 3, Time: 0.02925099991261959
Total Reward: [ 0.7 -3. ], Discounted: [ 0.6792093 -2.940399 ]
Scalarized Reward: -3.000000000000068, Discounted: -2.9403989315033625
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.08514399826526642
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 0.22984553752115744, Discounted: 0.09173792789933977
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.19780699908733368
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2565990090370178
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.25367000699043274
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.200531005859375
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.2860180139541626
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.25501999258995056
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.08501400053501129
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 0.22984553752115744, Discounted: 0.09173792789933977
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.196602001786232
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.2572939991950989
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.08627299964427948
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 0.22984553752115744, Discounted: 0.09173792789933977
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.23148299753665924
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.06971699744462967
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.08715800195932388
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 0.22984553752115744, Discounted: 0.09173792789933977
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.2009049952030182
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2804259955883026
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.25237300992012024
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2542110085487366
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.19761699438095093
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.2543869912624359
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.25459301471710205
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.19741100072860718
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.19811199605464935
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.26057401299476624
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
Episode infos:
Steps: 3, Time: 0.029541000723838806
Total Reward: [ 0.7 -3. ], Discounted: [ 0.6792093 -2.940399 ]
Scalarized Reward: -3.000000000000068, Discounted: -2.9403989315033625
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.20433799922466278
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.05757100135087967
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.19631999731063843
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
Episode infos:
Steps: 10, Time: 0.12689200043678284
Total Reward: [ 15.1 -10. ], Discounted: [13.65617  -9.466174]
Scalarized Reward: 3.585756385780832, Discounted: 3.0491457193228255
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.19972200691699982
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.19868500530719757
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.08622699975967407
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 0.22984553752115744, Discounted: 0.09173792789933977
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.2555850148200989
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.2830890119075775
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.28235599398612976
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.2795870006084442
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.25363901257514954
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.19751699268817902
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2578429877758026
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.282478004693985
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.08739499747753143
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 0.22984553752115744, Discounted: 0.09173792789933977
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.2525559961795807
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
Episode infos:
Steps: 3, Time: 0.029701000079512596
Total Reward: [ 0.7 -3. ], Discounted: [ 0.6792093 -2.940399 ]
Scalarized Reward: -3.000000000000068, Discounted: -2.9403989315033625
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.20287300646305084
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.20635999739170074
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.2824249863624573
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.19811999797821045
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2534559965133667
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.25457799434661865
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.20021800696849823
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.11966700106859207
Total Reward: [14. -9.], Discounted: [12.789242 -8.561792]
Scalarized Reward: 2.742957746478875, Discounted: 2.339263801843349
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
Episode infos:
Steps: 3, Time: 0.031539998948574066
Total Reward: [ 0.7 -3. ], Discounted: [ 0.6792093 -2.940399 ]
Scalarized Reward: -3.000000000000068, Discounted: -2.9403989315033625
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.20214800536632538
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.19802099466323853
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.0572969987988472
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.08571600168943405
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 0.22984553752115744, Discounted: 0.09173792789933977
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.25188401341438293
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.20645900070667267
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.20784799754619598
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.19934099912643433
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.256072998046875
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2569960057735443
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.0581509992480278
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.11419700086116791
Total Reward: [14. -9.], Discounted: [12.789242 -8.561792]
Scalarized Reward: 2.742957746478875, Discounted: 2.339263801843349
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.1979289948940277
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
Episode infos:
Steps: 3, Time: 0.02940399944782257
Total Reward: [ 0.7 -3. ], Discounted: [ 0.6792093 -2.940399 ]
Scalarized Reward: -3.000000000000068, Discounted: -2.9403989315033625
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.1128460019826889
Total Reward: [14. -9.], Discounted: [12.789242 -8.561792]
Scalarized Reward: 2.742957746478875, Discounted: 2.339263801843349
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.29155001044273376
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.06089799851179123
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
Episode infos:
Steps: 7, Time: 0.0898440033197403
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 1.6954031726724552, Discounted: 1.4736623308250394
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.2625879943370819
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
Episode infos:
Steps: 10, Time: 0.13491100072860718
Total Reward: [ 15.1 -10. ], Discounted: [13.65617  -9.466174]
Scalarized Reward: 3.585756385780832, Discounted: 3.0491457193228255
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.05764799937605858
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2517240047454834
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.19827300310134888
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
Episode infos:
Steps: 3, Time: 0.029694000259041786
Total Reward: [ 0.7 -3. ], Discounted: [ 0.6792093 -2.940399 ]
Scalarized Reward: -3.000000000000068, Discounted: -2.9403989315033625
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.2561039924621582
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
Episode infos:
Steps: 7, Time: 0.08553300052881241
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 1.6954031726724552, Discounted: 1.4736623308250394
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
Episode infos:
Steps: 7, Time: 0.0850600004196167
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 1.6954031726724552, Discounted: 1.4736623308250394
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.11264000087976456
Total Reward: [14. -9.], Discounted: [12.789242 -8.561792]
Scalarized Reward: 2.742957746478875, Discounted: 2.339263801843349
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.11399800330400467
Total Reward: [14. -9.], Discounted: [12.789242 -8.561792]
Scalarized Reward: 2.742957746478875, Discounted: 2.339263801843349
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.1974940001964569
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2536090016365051
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.08538799732923508
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 0.22984553752115744, Discounted: 0.09173792789933977
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.2805100083351135
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.05795300006866455
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.2839129865169525
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
Episode infos:
Steps: 10, Time: 0.12829600274562836
Total Reward: [ 15.1 -10. ], Discounted: [13.65617  -9.466174]
Scalarized Reward: 3.585756385780832, Discounted: 3.0491457193228255
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.19900499284267426
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.05862399935722351
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.2794190049171448
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.2952040135860443
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2595599889755249
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.11321999877691269
Total Reward: [14. -9.], Discounted: [12.789242 -8.561792]
Scalarized Reward: 2.742957746478875, Discounted: 2.339263801843349
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.25408199429512024
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.2824549973011017
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.25636300444602966
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.19780699908733368
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.057464998215436935
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.2561340034008026
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.19735699892044067
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.19689899682998657
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.19651800394058228
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2542499899864197
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.2816089987754822
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
Episode infos:
Steps: 10, Time: 0.1288830041885376
Total Reward: [ 15.1 -10. ], Discounted: [13.65617  -9.466174]
Scalarized Reward: 3.585756385780832, Discounted: 3.0491457193228255
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.28311899304389954
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.2526170015335083
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
Episode infos:
Steps: 3, Time: 0.029227999970316887
Total Reward: [ 0.7 -3. ], Discounted: [ 0.6792093 -2.940399 ]
Scalarized Reward: -3.000000000000068, Discounted: -2.9403989315033625
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.058205001056194305
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.252593994140625
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.27935001254081726
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.44328299164772034
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.08600600063800812
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 0.22984553752115744, Discounted: 0.09173792789933977
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
Episode infos:
Steps: 7, Time: 0.08632700145244598
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 1.6954031726724552, Discounted: 1.4736623308250394
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.25415000319480896
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.05828100070357323
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.25369301438331604
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.19799000024795532
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.11389899998903275
Total Reward: [14. -9.], Discounted: [12.789242 -8.561792]
Scalarized Reward: 2.742957746478875, Discounted: 2.339263801843349
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
Episode infos:
Steps: 10, Time: 0.1271969974040985
Total Reward: [ 15.1 -10. ], Discounted: [13.65617  -9.466174]
Scalarized Reward: 3.585756385780832, Discounted: 3.0491457193228255
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.28848299384117126
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2670440077781677
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.12071999907493591
Total Reward: [14. -9.], Discounted: [12.789242 -8.561792]
Scalarized Reward: 2.742957746478875, Discounted: 2.339263801843349
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.26357999444007874
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
Episode infos:
Steps: 7, Time: 0.08615099638700485
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 1.6954031726724552, Discounted: 1.4736623308250394
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.19847099483013153
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.25273099541664124
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.19694499671459198
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.20409399271011353
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.2070239931344986
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.19733400642871857
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.19818100333213806
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.11434900015592575
Total Reward: [14. -9.], Discounted: [12.789242 -8.561792]
Scalarized Reward: 2.742957746478875, Discounted: 2.339263801843349
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.25720998644828796
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.19973799586296082
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.11443299800157547
Total Reward: [14. -9.], Discounted: [12.789242 -8.561792]
Scalarized Reward: 2.742957746478875, Discounted: 2.339263801843349
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.19813500344753265
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.25244900584220886
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2, 1]	utility_threshold:-2.970099985599585
Episode infos:
Steps: 3, Time: 0.030136000365018845
Total Reward: [ 0.7 -3. ], Discounted: [ 0.6792093 -2.940399 ]
Scalarized Reward: -3.000000000000068, Discounted: -2.9403989315033625
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2555620074272156
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.28095200657844543
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.25637099146842957
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2687990069389343
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.26635000109672546
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.11349499970674515
Total Reward: [14. -9.], Discounted: [12.789242 -8.561792]
Scalarized Reward: 2.742957746478875, Discounted: 2.339263801843349
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1, 1]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.057395998388528824
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.2615810036659241
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.09124799817800522
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 0.22984553752115744, Discounted: 0.09173792789933977
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.21128100156784058
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.26807400584220886
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2556380033493042
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.28025099635124207
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.11495999991893768
Total Reward: [14. -9.], Discounted: [12.789242 -8.561792]
Scalarized Reward: 2.742957746478875, Discounted: 2.339263801843349
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
Episode infos:
Steps: 10, Time: 0.13001300394535065
Total Reward: [ 15.1 -10. ], Discounted: [13.65617  -9.466174]
Scalarized Reward: 3.585756385780832, Discounted: 3.0491457193228255
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2564089894294739
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
Episode infos:
Steps: 10, Time: 0.127593994140625
Total Reward: [ 15.1 -10. ], Discounted: [13.65617  -9.466174]
Scalarized Reward: 3.585756385780832, Discounted: 3.0491457193228255
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.08525799959897995
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 0.22984553752115744, Discounted: 0.09173792789933977
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
Episode infos:
Steps: 10, Time: 0.127593994140625
Total Reward: [ 15.1 -10. ], Discounted: [13.65617  -9.466174]
Scalarized Reward: 3.585756385780832, Discounted: 3.0491457193228255
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.25364699959754944
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.1974789947271347
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.11334200203418732
Total Reward: [14. -9.], Discounted: [12.789242 -8.561792]
Scalarized Reward: 2.742957746478875, Discounted: 2.339263801843349
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.1992799937725067
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.28279098868370056
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.19814300537109375
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
Episode infos:
Steps: 7, Time: 0.08647900074720383
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 1.6954031726724552, Discounted: 1.4736623308250394
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.2821269929409027
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.11390700191259384
Total Reward: [14. -9.], Discounted: [12.789242 -8.561792]
Scalarized Reward: 2.742957746478875, Discounted: 2.339263801843349
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2536320090293884
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.2556689977645874
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.19782300293445587
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.25499698519706726
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
Episode infos:
Steps: 7, Time: 0.08587600290775299
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 1.6954031726724552, Discounted: 1.4736623308250394
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.2824859917163849
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.25638601183891296
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:3.0799445854753387
Episode infos:
Steps: 10, Time: 0.12918899953365326
Total Reward: [ 15.1 -10. ], Discounted: [13.65617  -9.466174]
Scalarized Reward: 3.585756385780832, Discounted: 3.0491457193228255
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.19869199395179749
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
Episode infos:
Steps: 7, Time: 0.08532000333070755
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 1.6954031726724552, Discounted: 1.4736623308250394
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.26096299290657043
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.2952420115470886
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.20883899927139282
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1, 1]	utility_threshold:1.488547602325641
Episode infos:
Steps: 7, Time: 0.09191100299358368
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 1.6954031726724552, Discounted: 1.4736623308250394
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1, 1]	utility_threshold:2.362892414062797
Adding value: [  0.        -63.3967658] to CCS.
Value [  0.        -63.3967658] is dominated. Discarding.
Adding value: [  0.        -63.3967658] to CCS.
Value [  0.        -63.3967658] is dominated. Discarding.
Adding value: [  0.        -63.3967658] to CCS.
Value [  0.        -63.3967658] is dominated. Discarding.
Adding value: [  0.        -63.3967658] to CCS.
Value [  0.        -63.3967658] is dominated. Discarding.
Adding value: [  0.        -63.3967658] to CCS.
Value [  0.        -63.3967658] is dominated. Discarding.
Adding value: [  0.        -63.3967658] to CCS.
Value [  0.        -63.3967658] is dominated. Discarding.
Adding value: [  0.        -63.3967658] to CCS.
Value [  0.        -63.3967658] is dominated. Discarding.
Adding value: [  0.        -63.3967658] to CCS.
Value [  0.        -63.3967658] is dominated. Discarding.
Adding value: [  0.        -63.3967658] to CCS.
Value [  0.        -63.3967658] is dominated. Discarding.
Adding value: [  0.        -63.3967658] to CCS.
Value [  0.        -63.3967658] is dominated. Discarding.
Adding value: [ 0.69999999 -1.        ] to CCS.
removed value [ 17.45918465 -14.85422283]
removed value [ 14.56055164 -10.46617454]
removed value [ 7.87688732 -4.90099502]
removed value [ 0.68606997 -2.97009999]
Adding value: [  0.        -63.3967658] to CCS.
Value [  0.        -63.3967658] is dominated. Discarding.
Adding value: [  0.        -63.3967658] to CCS.
Value [  0.        -63.3967658] is dominated. Discarding.
Adding value: [  0.        -63.3967658] to CCS.
Value [  0.        -63.3967658] is dominated. Discarding.
Adding value: [  0.        -63.3967658] to CCS.
Value [  0.        -63.3967658] is dominated. Discarding.
Adding value: [  0.        -63.3967658] to CCS.
Value [  0.        -63.3967658] is dominated. Discarding.
