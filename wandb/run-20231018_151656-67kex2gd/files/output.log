{'env_id': 'deep-sea-treasure-v0', 'learning_rate': 0.0003, 'initial_epsilon': 0.01, 'epsilon_decay_steps:': None, 'batch_size': 128, 'per': True, 'gpi_pd': False, 'alpha_per': 0.6, 'min_priority': 0.01, 'tau': 1.0, 'num_nets': 2, 'clip_grand_norm': None, 'target_net_update_freq': 1000, 'gamma': 0.99, 'net_arch': [256, 256, 256, 256], 'dynamics_model_arch': [256, 256, 256], 'gradient_updates': 20, 'buffer_size': 1000000, 'learning_starts': 100, 'dyna': False, 'dynamics_rollout_len': 1, 'dynamics_uncertainty_threshold': 1.5, 'dynamics_rollout_starts': 5000, 'dynamics_rollout_freq': 250, 'dynamics_rollout_batch_size': 25000, 'dynamics_buffer_size': 100000, 'dynamics_normalize_inputs': False, 'dynamics_ensemble_size': 5, 'dynamics_num_elites': 2, 'real_ratio': 0.5, 'drop_rate': 0.01, 'layer_norm': True, 'seed': 42}
Training starts... Let's roll!
gpi_pd:False
from 10 demos, find 11 corner weights
w:[0. 1.]
w:[0.212 0.788]
w:[0.391 0.609]
w:[0.47 0.53]
w:[0.511 0.489]
w:[0.541 0.459]
w:[0.589 0.411]
w:[0.666 0.334]
w:[0.672 0.328]
w:[0.704 0.296]
w:[1. 0.]
rews_demo_dict:{0: {'rew_vec': array([ 0.68606997, -2.97009999]), 'demo': [2, 2, 1], 'demo_horizon': 3}, 1: {'rew_vec': array([ 7.87688732, -4.90099502]), 'demo': [2, 2, 3, 1, 1], 'demo_horizon': 5}, 2: {'rew_vec': array([10.8270216, -6.7934652]), 'demo': [2, 2, 3, 3, 1, 1, 1], 'demo_horizon': 7}, 3: {'rew_vec': array([12.91842556, -8.64827526]), 'demo': [2, 2, 3, 3, 3, 1, 1, 1, 1], 'demo_horizon': 9}, 4: {'rew_vec': array([13.7941103 , -9.56179249]), 'demo': [2, 2, 3, 3, 3, 3, 1, 1, 1, 1], 'demo_horizon': 10}, 5: {'rew_vec': array([ 14.56055164, -10.46617454]), 'demo': [2, 2, 3, 3, 3, 3, 3, 1, 1, 1, 1], 'demo_horizon': 11}, 6: {'rew_vec': array([ 17.02741814, -13.99416447]), 'demo': [2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1], 'demo_horizon': 15}, 7: {'rew_vec': array([ 17.45918465, -14.85422283]), 'demo': [2, 2, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1], 'demo_horizon': 16}, 8: {'rew_vec': array([ 18.6931076 , -17.38313758]), 'demo': [2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'demo_horizon': 19}, 9: {'rew_vec': array([ 19.38439369, -19.0272131 ]), 'demo': [2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'demo_horizon': 21}}
W_corner: [array([1., 0.]), array([0.39080246, 0.60919754]), array([0.51056338, 0.48943662]), array([0.58851004, 0.41148996]), array([0.70399075, 0.29600925]), array([0.6720793, 0.3279207]), array([0.66573773, 0.33426227]), array([0.54126519, 0.45873481]), array([0.47002179, 0.52997821]), array([0.21168203, 0.78831797]), array([0., 1.])] W_corner size: 11
CCS: [array([ 0.68606997, -2.97009999]), array([ 7.87688732, -4.90099502]), array([10.8270216, -6.7934652]), array([12.91842556, -8.64827526]), array([13.7941103 , -9.56179249]), array([ 14.56055164, -10.46617454]), array([ 17.02741814, -13.99416447]), array([ 17.45918465, -14.85422283]), array([ 18.6931076 , -17.38313758]), array([ 19.38439369, -19.0272131 ])] CCS size: 10
Next weight: [1. 0.]
Next weight vector: [1. 0.]
change_w_every_episode:True
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 100, Time: 0.1571200042963028
Total Reward: [   0. -100.], Discounted: [  0.       -62.762794]
Scalarized Reward: 0.0, Discounted: 0.0
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.21485500037670135
Total Reward: [11.5 -9. ], Discounted: [10.505448 -8.561792]
Scalarized Reward: 1.466549295774647, Discounted: 1.173242498451554
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 58, Time: 0.859935998916626
Total Reward: [ 16.1 -58. ], Discounted: [  8.988085 -43.731647]
Scalarized Reward: -5.8342850787126235, Discounted: -6.617443565351617
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
Episode infos:
Steps: 11, Time: 0.14677800238132477
Total Reward: [ 11.5 -11. ], Discounted: [ 10.29639  -10.361512]
Scalarized Reward: 1.1784666945957092, Discounted: 0.8198908652827619
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 31, Time: 0.44053301215171814
Total Reward: [ 19.6 -31. ], Discounted: [ 14.353147 -26.501963]
Scalarized Reward: 2.6863294070786345, Discounted: 0.6968250180163267
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
Episode infos:
Steps: 11, Time: 0.145236998796463
Total Reward: [ 11.5 -11. ], Discounted: [ 10.29639  -10.361512]
Scalarized Reward: 1.1784666945957092, Discounted: 0.8198908652827619
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.26024600863456726
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.20187799632549286
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.11626400053501129
Total Reward: [11.5 -9. ], Discounted: [10.505448 -8.561792]
Scalarized Reward: 1.466549295774647, Discounted: 1.173242498451554
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.2867549955844879
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.259552001953125
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
Episode infos:
Steps: 11, Time: 0.1463010013103485
Total Reward: [ 11.5 -11. ], Discounted: [ 10.29639  -10.361512]
Scalarized Reward: 1.1784666945957092, Discounted: 0.8198908652827619
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.2914699912071228
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.12117400020360947
Total Reward: [11.5 -9. ], Discounted: [10.505448 -8.561792]
Scalarized Reward: 1.466549295774647, Discounted: 1.173242498451554
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.11975900083780289
Total Reward: [11.5 -9. ], Discounted: [10.505448 -8.561792]
Scalarized Reward: 1.466549295774647, Discounted: 1.173242498451554
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
Episode infos:
Steps: 7, Time: 0.08793999999761581
Total Reward: [ 8.2 -7. ], Discounted: [ 7.6429358 -6.7255306]
Scalarized Reward: 0.14433116573539007, Discounted: 0.027961706596797864
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.20031000673770905
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.20019200444221497
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.28630098700523376
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.20783600211143494
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 7, Time: 0.09184300154447556
Total Reward: [ 0.7 -7. ], Discounted: [ 0.65244573 -6.7255306 ]
Scalarized Reward: -5.370048348774756, Discounted: -5.163745589852256
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.11914800107479095
Total Reward: [11.5 -9. ], Discounted: [10.505448 -8.561792]
Scalarized Reward: 1.466549295774647, Discounted: 1.173242498451554
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.26421698927879333
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.28953900933265686
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2]	utility_threshold:-2.970099985599585
Episode infos:
Steps: 4, Time: 0.04770300164818764
Total Reward: [ 0.7 -4. ], Discounted: [ 0.6724172 -3.900995 ]
Scalarized Reward: -4.000000000000091, Discounted: -3.900995016098111
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.2017589956521988
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.19935600459575653
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.2006949931383133
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.09029799699783325
Total Reward: [ 8.2 -7. ], Discounted: [ 7.6429358 -6.7255306]
Scalarized Reward: -1.0598026599276826, Discounted: -1.110298596354859
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2692910134792328
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.3094330132007599
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.3268589973449707
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.2029300034046173
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.08760800212621689
Total Reward: [ 8.2 -7. ], Discounted: [ 7.6429358 -6.7255306]
Scalarized Reward: -1.0598026599276826, Discounted: -1.110298596354859
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2618289887905121
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.19944800436496735
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.2851870059967041
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.28362300992012024
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.28756698966026306
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.20110300183296204
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2565230131149292
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.25868600606918335
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.25684699416160583
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.20124399662017822
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.11686699837446213
Total Reward: [11.5 -9. ], Discounted: [10.505448 -8.561792]
Scalarized Reward: 1.466549295774647, Discounted: 1.173242498451554
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.20242300629615784
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2573089897632599
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.11605799943208694
Total Reward: [11.5 -9. ], Discounted: [10.505448 -8.561792]
Scalarized Reward: 1.466549295774647, Discounted: 1.173242498451554
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.20043200254440308
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.2005770057439804
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.2866779863834381
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.060405999422073364
Total Reward: [ 0.7 -5. ], Discounted: [ 0.66569304 -4.851985  ]
Scalarized Reward: -3.7934124146835053, Discounted: -3.6839916767561074
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.2568359971046448
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.25661501288414
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.28684601187705994
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.08910399675369263
Total Reward: [ 8.2 -7. ], Discounted: [ 7.6429358 -6.7255306]
Scalarized Reward: -1.0598026599276826, Discounted: -1.110298596354859
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.11857599765062332
Total Reward: [11.5 -9. ], Discounted: [10.505448 -8.561792]
Scalarized Reward: 1.466549295774647, Discounted: 1.173242498451554
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.08946199715137482
Total Reward: [ 8.2 -7. ], Discounted: [ 7.6429358 -6.7255306]
Scalarized Reward: -1.0598026599276826, Discounted: -1.110298596354859
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3, 1]	utility_threshold:-2.1961469060292815
roll back guide policy; from [2, 2, 3, 1]
TO: [2, 2, 3]
Episode infos:
Steps: 5, Time: 0.05900600180029869
Total Reward: [ 0.7 -5. ], Discounted: [ 0.66569304 -4.851985  ]
Scalarized Reward: -3.7934124146835053, Discounted: -3.6839916767561074
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.20959100127220154
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2]	utility_threshold:-2.970099985599585
Episode infos:
Steps: 3, Time: 0.03242100030183792
Total Reward: [ 0.7 -3. ], Discounted: [ 0.6792093 -2.940399 ]
Scalarized Reward: -3.000000000000068, Discounted: -2.9403989315033625
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2586590051651001
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
Episode infos:
Steps: 10, Time: 0.1360740065574646
Total Reward: [ 15.1 -10. ], Discounted: [13.65617  -9.466174]
Scalarized Reward: 3.585756385780832, Discounted: 3.0491457193228255
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.06140900030732155
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
Episode infos:
Steps: 10, Time: 0.13131000101566315
Total Reward: [ 15.1 -10. ], Discounted: [13.65617  -9.466174]
Scalarized Reward: 3.585756385780832, Discounted: 3.0491457193228255
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.20410199463367462
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.21133799850940704
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.2050970047712326
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.26059699058532715
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
Episode infos:
Steps: 7, Time: 0.08776500076055527
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 1.6954031726724552, Discounted: 1.4736623308250394
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.25784701108932495
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.05960800126194954
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.1997150033712387
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.059856001287698746
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2593879997730255
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.2046699970960617
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.2051279991865158
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.20194999873638153
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.05996299907565117
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.11648599803447723
Total Reward: [14. -9.], Discounted: [12.789242 -8.561792]
Scalarized Reward: 2.742957746478875, Discounted: 2.339263801843349
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2]	utility_threshold:-2.970099985599585
Episode infos:
Steps: 3, Time: 0.03026599995791912
Total Reward: [ 0.7 -3. ], Discounted: [ 0.6792093 -2.940399 ]
Scalarized Reward: -3.000000000000068, Discounted: -2.9403989315033625
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
Episode infos:
Steps: 7, Time: 0.08920300006866455
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 1.6954031726724552, Discounted: 1.4736623308250394
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.060012999922037125
Total Reward: [ 0.7 -5. ], Discounted: [ 0.66569304 -4.851985  ]
Scalarized Reward: -3.7934124146835053, Discounted: -3.6839916767561074
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.255730003118515
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.2031559944152832
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
Episode infos:
Steps: 7, Time: 0.08795899897813797
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 1.6954031726724552, Discounted: 1.4736623308250394
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.2880859971046448
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.05963899940252304
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.08700600266456604
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 0.22984553752115744, Discounted: 0.09173792789933977
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.087677001953125
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 0.22984553752115744, Discounted: 0.09173792789933977
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.08779899775981903
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 0.22984553752115744, Discounted: 0.09173792789933977
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2577129900455475
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.2712329924106598
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.3203960061073303
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2]	utility_threshold:-2.970099985599585
Episode infos:
Steps: 3, Time: 0.036354001611471176
Total Reward: [ 0.7 -3. ], Discounted: [ 0.6792093 -2.940399 ]
Scalarized Reward: -3.000000000000068, Discounted: -2.9403989315033625
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.09966299682855606
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 0.22984553752115744, Discounted: 0.09173792789933977
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.22669200599193573
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2924189865589142
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2911219894886017
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.22934700548648834
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.3251500129699707
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.2921069860458374
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.10040999948978424
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 0.22984553752115744, Discounted: 0.09173792789933977
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.22795100510120392
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.29056599736213684
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.10101299732923508
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 0.22984553752115744, Discounted: 0.09173792789933977
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.22948500514030457
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.07228899747133255
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.10018199682235718
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 0.22984553752115744, Discounted: 0.09173792789933977
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.22859199345111847
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2921450138092041
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.2945939898490906
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.291130006313324
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.22487600147724152
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.29315999150276184
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2907409965991974
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.232231006026268
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.2335360050201416
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.28623199462890625
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2]	utility_threshold:-2.970099985599585
Episode infos:
Steps: 3, Time: 0.03521699830889702
Total Reward: [ 0.7 -3. ], Discounted: [ 0.6792093 -2.940399 ]
Scalarized Reward: -3.000000000000068, Discounted: -2.9403989315033625
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.22620399296283722
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.06926000118255615
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.2244420051574707
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
Episode infos:
Steps: 10, Time: 0.14909400045871735
Total Reward: [ 15.1 -10. ], Discounted: [13.65617  -9.466174]
Scalarized Reward: 3.585756385780832, Discounted: 3.0491457193228255
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.22667700052261353
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.2256769984960556
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.10035700350999832
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 0.22984553752115744, Discounted: 0.09173792789933977
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.28971898555755615
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.3189469873905182
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.3163830041885376
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.3160020112991333
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2790980041027069
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.20472000539302826
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2770079970359802
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.3229140043258667
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.08705899864435196
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 0.22984553752115744, Discounted: 0.09173792789933977
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.25933098793029785
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2]	utility_threshold:-2.970099985599585
Episode infos:
Steps: 3, Time: 0.030693000182509422
Total Reward: [ 0.7 -3. ], Discounted: [ 0.6792093 -2.940399 ]
Scalarized Reward: -3.000000000000068, Discounted: -2.9403989315033625
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.20085899531841278
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.19983699917793274
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.28582799434661865
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.2000119984149933
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2585679888725281
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.255744993686676
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.20079800486564636
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.11473800241947174
Total Reward: [14. -9.], Discounted: [12.789242 -8.561792]
Scalarized Reward: 2.742957746478875, Discounted: 2.339263801843349
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2]	utility_threshold:-2.970099985599585
Episode infos:
Steps: 3, Time: 0.03023499995470047
Total Reward: [ 0.7 -3. ], Discounted: [ 0.6792093 -2.940399 ]
Scalarized Reward: -3.000000000000068, Discounted: -2.9403989315033625
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.200095996260643
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.2017820030450821
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.06082199886441231
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.08731099963188171
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 0.22984553752115744, Discounted: 0.09173792789933977
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.26543399691581726
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.21063199639320374
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.20109599828720093
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.2001499980688095
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2578510046005249
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.25591298937797546
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.05879199877381325
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.11539500206708908
Total Reward: [14. -9.], Discounted: [12.789242 -8.561792]
Scalarized Reward: 2.742957746478875, Discounted: 2.339263801843349
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.199195995926857
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2]	utility_threshold:-2.970099985599585
Episode infos:
Steps: 3, Time: 0.0303569994866848
Total Reward: [ 0.7 -3. ], Discounted: [ 0.6792093 -2.940399 ]
Scalarized Reward: -3.000000000000068, Discounted: -2.9403989315033625
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.1150130033493042
Total Reward: [14. -9.], Discounted: [12.789242 -8.561792]
Scalarized Reward: 2.742957746478875, Discounted: 2.339263801843349
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.2851260006427765
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.05932600051164627
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
Episode infos:
Steps: 7, Time: 0.08823399990797043
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 1.6954031726724552, Discounted: 1.4736623308250394
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.254364013671875
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
Episode infos:
Steps: 10, Time: 0.13090500235557556
Total Reward: [ 15.1 -10. ], Discounted: [13.65617  -9.466174]
Scalarized Reward: 3.585756385780832, Discounted: 3.0491457193228255
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.059464000165462494
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2574619948863983
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.19935600459575653
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2]	utility_threshold:-2.970099985599585
Episode infos:
Steps: 3, Time: 0.030295999720692635
Total Reward: [ 0.7 -3. ], Discounted: [ 0.6792093 -2.940399 ]
Scalarized Reward: -3.000000000000068, Discounted: -2.9403989315033625
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.25450098514556885
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
Episode infos:
Steps: 7, Time: 0.08644100278615952
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 1.6954031726724552, Discounted: 1.4736623308250394
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
Episode infos:
Steps: 7, Time: 0.08695200085639954
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 1.6954031726724552, Discounted: 1.4736623308250394
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.11551699787378311
Total Reward: [14. -9.], Discounted: [12.789242 -8.561792]
Scalarized Reward: 2.742957746478875, Discounted: 2.339263801843349
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.11658500134944916
Total Reward: [14. -9.], Discounted: [12.789242 -8.561792]
Scalarized Reward: 2.742957746478875, Discounted: 2.339263801843349
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.198730006814003
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.25714901089668274
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.08660099655389786
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 0.22984553752115744, Discounted: 0.09173792789933977
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.2838209867477417
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.05912800133228302
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.28324899077415466
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
Episode infos:
Steps: 10, Time: 0.12908899784088135
Total Reward: [ 15.1 -10. ], Discounted: [13.65617  -9.466174]
Scalarized Reward: 3.585756385780832, Discounted: 3.0491457193228255
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.19731900095939636
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.059852998703718185
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.28496599197387695
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.2816239893436432
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2607649862766266
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
w:tensor([0.5106, 0.4894], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 1, 1, 1]	utility_threshold:2.362892414062797
Episode infos:
Steps: 9, Time: 0.12253600358963013
Total Reward: [14. -9.], Discounted: [12.789242 -8.561792]
Scalarized Reward: 2.742957746478875, Discounted: 2.339263801843349
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.2790830135345459
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.2911989986896515
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.2655560076236725
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.19911199808120728
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.06008100137114525
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.19973799586296082
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
w:tensor([0.6657, 0.3343], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:6.658073525843035
Episode infos:
Steps: 15, Time: 0.19984400272369385
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 8.034525722297658, Discounted: 6.591492597671896
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
Episode infos:
Steps: 19, Time: 0.25684401392936707
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 10.145216824880412, Discounted: 7.934063346028475
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.2843480110168457
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
w:tensor([0.5413, 0.4587], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 1, 1, 1]	utility_threshold:3.0799445854753387
Episode infos:
Steps: 10, Time: 0.1336439996957779
Total Reward: [ 15.1 -10. ], Discounted: [13.65617  -9.466174]
Scalarized Reward: 3.585756385780832, Discounted: 3.0491457193228255
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.31700098514556885
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.2602689862251282
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2]	utility_threshold:-2.970099985599585
w:tensor([0., 1.], device='cuda:0')	guide_policy:[2, 2]	utility_threshold:-2.970099985599585
Episode infos:
Steps: 3, Time: 0.03173099830746651
Total Reward: [ 0.7 -3. ], Discounted: [ 0.6792093 -2.940399 ]
Scalarized Reward: -3.000000000000068, Discounted: -2.9403989315033625
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.06111900135874748
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.25638601183891296
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
w:tensor([1., 0.], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:19.384393692016644
Episode infos:
Steps: 21, Time: 0.28494301438331604
Total Reward: [ 23.7 -21. ], Discounted: [ 19.190552 -18.83694 ]
Scalarized Reward: 23.700000762939506, Discounted: 19.190551757812543
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
w:tensor([0.5885, 0.4115], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]	utility_threshold:4.262348415137681
Episode infos:
Steps: 15, Time: 0.20418499410152435
Total Reward: [ 19.6 -15. ], Discounted: [ 16.857143 -13.854222]
Scalarized Reward: 5.36244767895918, Discounted: 4.219724821298167
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
w:tensor([0.3908, 0.6092], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:0.09266441536255066
Episode infos:
Steps: 7, Time: 0.08692199736833572
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 0.22984553752115744, Discounted: 0.09173792789933977
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
w:tensor([0.4700, 0.5300], device='cuda:0')	guide_policy:[2, 2, 3, 3, 1, 1]	utility_threshold:1.488547602325641
Episode infos:
Steps: 7, Time: 0.0894550010561943
Total Reward: [11.5 -7. ], Discounted: [10.718752  -6.7255306]
Scalarized Reward: 1.6954031726724552, Discounted: 1.4736623308250394
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
w:tensor([0.6721, 0.3279], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:6.86296012481859
Episode infos:
Steps: 19, Time: 0.2582550048828125
Total Reward: [ 22.4 -19. ], Discounted: [ 18.506176 -17.209305]
Scalarized Reward: 8.824082873206427, Discounted: 6.794330623181032
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
w:tensor([0.2117, 0.7883], device='cuda:0')	guide_policy:[2, 2, 3]	utility_threshold:-2.1961469060292815
Episode infos:
Steps: 5, Time: 0.060683999210596085
Total Reward: [ 8.2 -5. ], Discounted: [ 7.798118 -4.851985]
Scalarized Reward: -2.2057972053773085, Discounted: -2.1741854380841192
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
w:tensor([0.7040, 0.2960], device='cuda:0')	guide_policy:[2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]	utility_threshold:8.014205361699974
